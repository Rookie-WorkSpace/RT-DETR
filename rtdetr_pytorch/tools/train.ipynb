{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  \n",
    "# 增加PIL的解压炸弹限制\n",
    "Image.MAX_IMAGE_PIXELS = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA版本配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 添加cuda环境变量\n",
    "os.environ[\"CUDA_PATH\"] = r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\"\n",
    "\n",
    "# 添加cudnn环境变量\n",
    "cudnn_paths = [\n",
    "             r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin\",\n",
    "             r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\libnvvp\",\n",
    "             r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\include\",\n",
    "             r\"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\lib\",\n",
    "            ]\n",
    "for cudnn_path in cudnn_paths:\n",
    "    if cudnn_path not in os.environ[\"PATH\"]:\n",
    "        os.environ[\"PATH\"] = cudnn_path + os.pathsep + os.environ[\"PATH\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\include;c:\\Users\\Rooki\\.conda\\envs\\rtdetr;C:\\Users\\Rooki\\.conda\\envs\\rtdetr;C:\\Users\\Rooki\\.conda\\envs\\rtdetr\\Library\\mingw-w64\\bin;C:\\Users\\Rooki\\.conda\\envs\\rtdetr\\Library\\usr\\bin;C:\\Users\\Rooki\\.conda\\envs\\rtdetr\\Library\\bin;C:\\Users\\Rooki\\.conda\\envs\\rtdetr\\Scripts;C:\\Users\\Rooki\\.conda\\envs\\rtdetr\\bin;C:\\ProgramData\\miniconda3\\condabin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\\libnvvp;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\\libnvvp;.;C:\\windows\\system32;C:\\windows;C:\\windows\\System32\\Wbem;C:\\windows\\System32\\WindowsPowerShell\\v1.0;C:\\windows\\System32\\OpenSSH;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\Users\\Administrator\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\HP\\OMEN-Broadcast\\Common;C:\\Program Files\\Git\\cmd;c:\\Users\\Rooki\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\Program Files (x86)\\NetSarang\\Xshell 8;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2022.3.0;C:\\Users\\Rooki\\.local\\bin;C:\\Users\\Rooki\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\Rooki\\AppData\\Local\\Programs\\cursor\\resources\\app\\bin;C:\\ProgramData\\miniconda3;C:\\ProgramData\\miniconda3\\Scripts;C:\\ProgramData\\miniconda3\\Library\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\\libnvvp;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\\lib;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.1\\include;.\n",
      "C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.8\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Wed_Sep_21_10:41:10_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 11.8, V11.8.89\n",
      "Build cuda_11.8.r11.8/compiler.31833905_0\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"PATH\"])\n",
    "print(os.environ[\"CUDA_PATH\"])\n",
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available(): True\n",
      "torch.cuda.get_device_name(0): NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"torch.cuda.is_available(): {torch.cuda.is_available()}\")\n",
    "print(f\"torch.cuda.get_device_name(0): {torch.cuda.get_device_name(0)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Rooki\\.conda\\envs\\rtdetr\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 导入必要的库\n",
    "import os \n",
    "import sys \n",
    "# 将项目根目录添加到系统路径\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "import argparse\n",
    "\n",
    "# 导入自定义模块\n",
    "import src.misc.dist as dist \n",
    "from src.core import YAMLConfig \n",
    "from src.solver import TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Rooki\\\\Desktop\\\\AI\\\\CV\\\\RT-DETR\\\\rtdetr_pytorch'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "root_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在jupyter中直接设置参数\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.config = f'{root_dir}/configs/rtdetr/rtdetr_r50vd_6x_chengdu.yml'  # 配置文件路径\n",
    "        self.resume = None  # 恢复训练的检查点路径\n",
    "        self.tuning = None  # 微调模式的预训练模型路径\n",
    "        self.test_only = False  # 是否只执行测试\n",
    "        self.amp = False  # 是否启用自动混合精度\n",
    "        self.seed = None  # 随机种子\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not init distributed mode.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'task': 'detection',\n",
       " 'num_classes': 17,\n",
       " 'remap_mscoco_category': True,\n",
       " 'train_dataloader': {'type': 'DataLoader',\n",
       "  'dataset': {'type': 'CocoDetection',\n",
       "   'img_folder': '\\\\\\\\?\\\\C:\\\\Users\\\\Rooki\\\\Desktop\\\\AI\\\\CV\\\\RT-DETR\\\\chengdu_dataset\\\\train',\n",
       "   'ann_file': '\\\\\\\\?\\\\C:\\\\Users\\\\Rooki\\\\Desktop\\\\AI\\\\CV\\\\RT-DETR\\\\chengdu_dataset\\\\train\\\\_annotations.coco.json',\n",
       "   'transforms': {'type': 'Compose',\n",
       "    'ops': [{'type': 'RandomPhotometricDistort', 'p': 0.5},\n",
       "     {'type': 'RandomZoomOut', 'fill': 0},\n",
       "     {'type': 'RandomIoUCrop', 'p': 0.8},\n",
       "     {'type': 'SanitizeBoundingBox', 'min_size': 1},\n",
       "     {'type': 'RandomHorizontalFlip'},\n",
       "     {'type': 'Resize', 'size': [640, 640]},\n",
       "     {'type': 'ToImageTensor'},\n",
       "     {'type': 'ConvertDtype'},\n",
       "     {'type': 'SanitizeBoundingBox', 'min_size': 1},\n",
       "     {'type': 'ConvertBox', 'out_fmt': 'cxcywh', 'normalize': True}]},\n",
       "   'return_masks': False},\n",
       "  'shuffle': True,\n",
       "  'batch_size': 4,\n",
       "  'num_workers': 4,\n",
       "  'drop_last': True,\n",
       "  'collate_fn': 'default_collate_fn'},\n",
       " 'val_dataloader': {'type': 'DataLoader',\n",
       "  'dataset': {'type': 'CocoDetection',\n",
       "   'img_folder': '\\\\\\\\?\\\\C:\\\\Users\\\\Rooki\\\\Desktop\\\\AI\\\\CV\\\\RT-DETR\\\\chengdu_dataset\\\\valid',\n",
       "   'ann_file': '\\\\\\\\?\\\\C:\\\\Users\\\\Rooki\\\\Desktop\\\\AI\\\\CV\\\\RT-DETR\\\\chengdu_dataset\\\\valid\\\\_annotations.coco.json',\n",
       "   'transforms': {'type': 'Compose',\n",
       "    'ops': [{'type': 'Resize', 'size': [640, 640]},\n",
       "     {'type': 'ToImageTensor'},\n",
       "     {'type': 'ConvertDtype'}]}},\n",
       "  'shuffle': False,\n",
       "  'batch_size': 8,\n",
       "  'num_workers': 4,\n",
       "  'drop_last': False,\n",
       "  'collate_fn': 'default_collate_fn'},\n",
       " 'sync_bn': True,\n",
       " 'find_unused_parameters': True,\n",
       " 'use_amp': False,\n",
       " 'scaler': {'type': 'GradScaler', 'enabled': True},\n",
       " 'use_ema': True,\n",
       " 'ema': {'type': 'ModelEMA', 'decay': 0.9999, 'warmups': 1},\n",
       " 'epoches': 1,\n",
       " 'clip_max_norm': 0.1,\n",
       " 'optimizer': {'type': 'AdamW',\n",
       "  'params': [{'params': 'backbone', 'lr': 1e-05},\n",
       "   {'params': '^(?=.*encoder(?=.*bias|.*norm.*weight)).*$',\n",
       "    'weight_decay': 0.0},\n",
       "   {'params': '^(?=.*decoder(?=.*bias|.*norm.*weight)).*$',\n",
       "    'weight_decay': 0.0}],\n",
       "  'lr': 0.0001,\n",
       "  'betas': [0.9, 0.999],\n",
       "  'weight_decay': 0.0001},\n",
       " 'lr_scheduler': {'type': 'MultiStepLR', 'milestones': [1000], 'gamma': 0.1},\n",
       " 'model': 'RTDETR',\n",
       " 'criterion': 'SetCriterion',\n",
       " 'postprocessor': 'RTDETRPostProcessor',\n",
       " 'RTDETR': {'backbone': 'PResNet',\n",
       "  'encoder': 'HybridEncoder',\n",
       "  'decoder': 'RTDETRTransformer',\n",
       "  'multi_scale': [480,\n",
       "   512,\n",
       "   544,\n",
       "   576,\n",
       "   608,\n",
       "   640,\n",
       "   640,\n",
       "   640,\n",
       "   672,\n",
       "   704,\n",
       "   736,\n",
       "   768,\n",
       "   800]},\n",
       " 'PResNet': {'depth': 50,\n",
       "  'variant': 'd',\n",
       "  'freeze_at': 0,\n",
       "  'return_idx': [1, 2, 3],\n",
       "  'num_stages': 4,\n",
       "  'freeze_norm': True,\n",
       "  'pretrained': True},\n",
       " 'HybridEncoder': {'in_channels': [512, 1024, 2048],\n",
       "  'feat_strides': [8, 16, 32],\n",
       "  'hidden_dim': 256,\n",
       "  'use_encoder_idx': [2],\n",
       "  'num_encoder_layers': 1,\n",
       "  'nhead': 8,\n",
       "  'dim_feedforward': 1024,\n",
       "  'dropout': 0.0,\n",
       "  'enc_act': 'gelu',\n",
       "  'pe_temperature': 10000,\n",
       "  'expansion': 1.0,\n",
       "  'depth_mult': 1,\n",
       "  'act': 'silu',\n",
       "  'eval_spatial_size': [640, 640]},\n",
       " 'RTDETRTransformer': {'feat_channels': [256, 256, 256],\n",
       "  'feat_strides': [8, 16, 32],\n",
       "  'hidden_dim': 256,\n",
       "  'num_levels': 3,\n",
       "  'num_queries': 300,\n",
       "  'num_decoder_layers': 6,\n",
       "  'num_denoising': 100,\n",
       "  'eval_idx': -1,\n",
       "  'eval_spatial_size': [640, 640]},\n",
       " 'use_focal_loss': True,\n",
       " 'RTDETRPostProcessor': {'num_top_queries': 300},\n",
       " 'SetCriterion': {'weight_dict': {'loss_vfl': 1,\n",
       "   'loss_bbox': 5,\n",
       "   'loss_giou': 2},\n",
       "  'losses': ['vfl', 'boxes'],\n",
       "  'alpha': 0.75,\n",
       "  'gamma': 2.0,\n",
       "  'matcher': {'type': 'HungarianMatcher',\n",
       "   'weight_dict': {'cost_class': 2, 'cost_bbox': 5, 'cost_giou': 2},\n",
       "   'alpha': 0.25,\n",
       "   'gamma': 2.0}},\n",
       " '__include__': ['../dataset/chengdu_detection.yml',\n",
       "  '../runtime.yml',\n",
       "  './include/dataloader.yml',\n",
       "  './include/optimizer.yml',\n",
       "  './include/rtdetr_r50vd.yml'],\n",
       " 'output_dir': './output/rtdetr_r50vd_6x_chengdu',\n",
       " 'resume': None,\n",
       " 'tuning': None}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 初始化分布式训练\n",
    "dist.init_distributed()\n",
    "\n",
    "# 如果指定了随机种子则设置\n",
    "if args.seed is not None:\n",
    "    dist.set_seed(args.seed)\n",
    "\n",
    "# 确保不同时使用tuning和resume模式\n",
    "assert not all([args.tuning, args.resume]), \\\n",
    "    'Only support from_scrach or resume or tuning at one time'\n",
    "\n",
    "# 创建配置对象\n",
    "cfg = YAMLConfig(\n",
    "    args.config,      # 配置文件路径\n",
    "    resume=args.resume,   # 是否从检查点恢复训练\n",
    "    use_amp=args.amp,     # 是否使用混合精度训练\n",
    "    tuning=args.tuning    # 是否使用微调模式\n",
    ")\n",
    "\n",
    "cfg.yaml_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'detection'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.yaml_cfg['task']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load PResNet50 state_dict\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "src.zoo.rtdetr.rtdetr.RTDETR"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cfg.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据配置创建对应任务的训练器\n",
    "solver = TASKS[cfg.yaml_cfg['task']](cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RTDETR(\n",
       "  (backbone): PResNet(\n",
       "    (conv1): Sequential(\n",
       "      (conv1_1): ConvNormLayer(\n",
       "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): FrozenBatchNorm2d(32, eps=1e-05)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv1_2): ConvNormLayer(\n",
       "        (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (norm): FrozenBatchNorm2d(32, eps=1e-05)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "      (conv1_3): ConvNormLayer(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (norm): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (res_layers): ModuleList(\n",
       "      (0): Blocks(\n",
       "        (blocks): ModuleList(\n",
       "          (0): BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (short): ConvNormLayer(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1-2): 2 x BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): Blocks(\n",
       "        (blocks): ModuleList(\n",
       "          (0): BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (short): Sequential(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (conv): ConvNormLayer(\n",
       "                (conv): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1-3): 3 x BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): Blocks(\n",
       "        (blocks): ModuleList(\n",
       "          (0): BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (short): Sequential(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (conv): ConvNormLayer(\n",
       "                (conv): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1-5): 5 x BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Blocks(\n",
       "        (blocks): ModuleList(\n",
       "          (0): BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (short): Sequential(\n",
       "              (pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "              (conv): ConvNormLayer(\n",
       "                (conv): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (norm): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "          (1-2): 2 x BottleNeck(\n",
       "            (branch2a): ConvNormLayer(\n",
       "              (conv): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2b): ConvNormLayer(\n",
       "              (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (branch2c): ConvNormLayer(\n",
       "              (conv): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): RTDETRTransformer(\n",
       "    (input_proj): ModuleList(\n",
       "      (0-2): 3 x Sequential(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder): TransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerDecoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (cross_attn): MSDeformableAttention(\n",
       "            (sampling_offsets): Linear(in_features=256, out_features=192, bias=True)\n",
       "            (attention_weights): Linear(in_features=256, out_features=96, bias=True)\n",
       "            (value_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (output_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (dropout3): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (dropout4): Dropout(p=0.0, inplace=False)\n",
       "          (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (denoising_class_embed): Embedding(18, 256, padding_idx=17)\n",
       "    (query_pos_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=4, out_features=512, bias=True)\n",
       "        (1): Linear(in_features=512, out_features=256, bias=True)\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (enc_output): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (enc_score_head): Linear(in_features=256, out_features=17, bias=True)\n",
       "    (enc_bbox_head): MLP(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "        (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "      )\n",
       "      (act): ReLU(inplace=True)\n",
       "    )\n",
       "    (dec_score_head): ModuleList(\n",
       "      (0-5): 6 x Linear(in_features=256, out_features=17, bias=True)\n",
       "    )\n",
       "    (dec_bbox_head): ModuleList(\n",
       "      (0-5): 6 x MLP(\n",
       "        (layers): ModuleList(\n",
       "          (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "          (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "        )\n",
       "        (act): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): HybridEncoder(\n",
       "    (input_proj): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder): ModuleList(\n",
       "      (0): TransformerEncoder(\n",
       "        (layers): ModuleList(\n",
       "          (0): TransformerEncoderLayer(\n",
       "            (self_attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "            (linear1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout1): Dropout(p=0.0, inplace=False)\n",
       "            (dropout2): Dropout(p=0.0, inplace=False)\n",
       "            (activation): GELU(approximate='none')\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (lateral_convs): ModuleList(\n",
       "      (0-1): 2 x ConvNormLayer(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (fpn_blocks): ModuleList(\n",
       "      (0-1): 2 x CSPRepLayer(\n",
       "        (conv1): ConvNormLayer(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvNormLayer(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (bottlenecks): Sequential(\n",
       "          (0): RepVggBlock(\n",
       "            (conv1): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (conv2): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): RepVggBlock(\n",
       "            (conv1): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (conv2): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): RepVggBlock(\n",
       "            (conv1): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (conv2): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): Identity()\n",
       "      )\n",
       "    )\n",
       "    (downsample_convs): ModuleList(\n",
       "      (0-1): 2 x ConvNormLayer(\n",
       "        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (pan_blocks): ModuleList(\n",
       "      (0-1): 2 x CSPRepLayer(\n",
       "        (conv1): ConvNormLayer(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (conv2): ConvNormLayer(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (bottlenecks): Sequential(\n",
       "          (0): RepVggBlock(\n",
       "            (conv1): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (conv2): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): RepVggBlock(\n",
       "            (conv1): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (conv2): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): RepVggBlock(\n",
       "            (conv1): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (conv2): ConvNormLayer(\n",
       "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): Identity()\n",
       "            )\n",
       "            (act): SiLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (conv3): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.cfg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RTDETRPostProcessor(use_focal_loss=True, num_classes=17, num_top_queries=300)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.cfg.postprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solver.val()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "Initial lr:  [1e-05, 0.0001, 0.0001, 0.0001]\n",
      "loading annotations into memory...\n",
      "Done (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "模型参数数量: 42733395\n",
      "Epoch: [0]  [   0/1348]  eta: 4:41:44  lr: 0.000010  loss: 32.1872 (32.1872)  loss_vfl: 0.2446 (0.2446)  loss_bbox: 0.5230 (0.5230)  loss_giou: 1.7820 (1.7820)  loss_vfl_aux_0: 0.2453 (0.2453)  loss_bbox_aux_0: 0.5734 (0.5734)  loss_giou_aux_0: 1.7573 (1.7573)  loss_vfl_aux_1: 0.2535 (0.2535)  loss_bbox_aux_1: 0.5223 (0.5223)  loss_giou_aux_1: 1.7907 (1.7907)  loss_vfl_aux_2: 0.2170 (0.2170)  loss_bbox_aux_2: 0.5070 (0.5070)  loss_giou_aux_2: 1.8338 (1.8338)  loss_vfl_aux_3: 0.2742 (0.2742)  loss_bbox_aux_3: 0.4943 (0.4943)  loss_giou_aux_3: 1.7994 (1.7994)  loss_vfl_aux_4: 0.2602 (0.2602)  loss_bbox_aux_4: 0.5297 (0.5297)  loss_giou_aux_4: 1.7572 (1.7572)  loss_vfl_aux_5: 0.2019 (0.2019)  loss_bbox_aux_5: 0.5331 (0.5331)  loss_giou_aux_5: 1.8132 (1.8132)  loss_vfl_dn_0: 0.7154 (0.7154)  loss_bbox_dn_0: 0.2350 (0.2350)  loss_giou_dn_0: 1.4250 (1.4250)  loss_vfl_dn_1: 0.7328 (0.7328)  loss_bbox_dn_1: 0.2350 (0.2350)  loss_giou_dn_1: 1.4250 (1.4250)  loss_vfl_dn_2: 0.7084 (0.7084)  loss_bbox_dn_2: 0.2350 (0.2350)  loss_giou_dn_2: 1.4250 (1.4250)  loss_vfl_dn_3: 0.7251 (0.7251)  loss_bbox_dn_3: 0.2350 (0.2350)  loss_giou_dn_3: 1.4250 (1.4250)  loss_vfl_dn_4: 0.7213 (0.7213)  loss_bbox_dn_4: 0.2350 (0.2350)  loss_giou_dn_4: 1.4250 (1.4250)  loss_vfl_dn_5: 0.7116 (0.7116)  loss_bbox_dn_5: 0.2350 (0.2350)  loss_giou_dn_5: 1.4250 (1.4250)  time: 12.5403  data: 11.0292  max mem: 2841\n",
      "Epoch: [0]  [ 100/1348]  eta: 0:12:32  lr: 0.000010  loss: 29.7528 (32.8303)  loss_vfl: 0.4772 (0.4566)  loss_bbox: 0.5150 (0.6672)  loss_giou: 1.5566 (1.6829)  loss_vfl_aux_0: 0.3936 (0.3680)  loss_bbox_aux_0: 0.5437 (0.6849)  loss_giou_aux_0: 1.5979 (1.6937)  loss_vfl_aux_1: 0.4333 (0.3920)  loss_bbox_aux_1: 0.5372 (0.6769)  loss_giou_aux_1: 1.5523 (1.6853)  loss_vfl_aux_2: 0.4431 (0.4224)  loss_bbox_aux_2: 0.5182 (0.6723)  loss_giou_aux_2: 1.5779 (1.6855)  loss_vfl_aux_3: 0.4887 (0.4363)  loss_bbox_aux_3: 0.5169 (0.6679)  loss_giou_aux_3: 1.5887 (1.6823)  loss_vfl_aux_4: 0.4773 (0.4419)  loss_bbox_aux_4: 0.5245 (0.6693)  loss_giou_aux_4: 1.5458 (1.6815)  loss_vfl_aux_5: 0.3476 (0.3303)  loss_bbox_aux_5: 0.5301 (0.6972)  loss_giou_aux_5: 1.5631 (1.7137)  loss_vfl_dn_0: 0.3792 (0.4742)  loss_bbox_dn_0: 0.2785 (0.3450)  loss_giou_dn_0: 1.3701 (1.3829)  loss_vfl_dn_1: 0.3796 (0.4629)  loss_bbox_dn_1: 0.2789 (0.3453)  loss_giou_dn_1: 1.3644 (1.3936)  loss_vfl_dn_2: 0.3969 (0.4776)  loss_bbox_dn_2: 0.2798 (0.3456)  loss_giou_dn_2: 1.3681 (1.4047)  loss_vfl_dn_3: 0.4095 (0.4820)  loss_bbox_dn_3: 0.2803 (0.3460)  loss_giou_dn_3: 1.3785 (1.4187)  loss_vfl_dn_4: 0.4559 (0.4876)  loss_bbox_dn_4: 0.2805 (0.3465)  loss_giou_dn_4: 1.3804 (1.4343)  loss_vfl_dn_5: 0.4402 (0.4768)  loss_bbox_dn_5: 0.2803 (0.3471)  loss_giou_dn_5: 1.3845 (1.4513)  time: 0.4633  data: 0.0043  max mem: 5453\n",
      "Epoch: [0]  [ 200/1348]  eta: 0:10:29  lr: 0.000010  loss: 28.7585 (31.8480)  loss_vfl: 0.3863 (0.4648)  loss_bbox: 0.3966 (0.6179)  loss_giou: 1.5879 (1.6363)  loss_vfl_aux_0: 0.3417 (0.3730)  loss_bbox_aux_0: 0.4486 (0.6394)  loss_giou_aux_0: 1.5968 (1.6534)  loss_vfl_aux_1: 0.3528 (0.3906)  loss_bbox_aux_1: 0.4280 (0.6313)  loss_giou_aux_1: 1.6125 (1.6457)  loss_vfl_aux_2: 0.3563 (0.4129)  loss_bbox_aux_2: 0.4382 (0.6297)  loss_giou_aux_2: 1.5886 (1.6440)  loss_vfl_aux_3: 0.3647 (0.4280)  loss_bbox_aux_3: 0.4342 (0.6241)  loss_giou_aux_3: 1.5953 (1.6400)  loss_vfl_aux_4: 0.3994 (0.4466)  loss_bbox_aux_4: 0.3921 (0.6222)  loss_giou_aux_4: 1.6076 (1.6346)  loss_vfl_aux_5: 0.2982 (0.3458)  loss_bbox_aux_5: 0.4500 (0.6527)  loss_giou_aux_5: 1.6393 (1.6725)  loss_vfl_dn_0: 0.3778 (0.4298)  loss_bbox_dn_0: 0.2311 (0.3359)  loss_giou_dn_0: 1.3388 (1.3736)  loss_vfl_dn_1: 0.3808 (0.4251)  loss_bbox_dn_1: 0.2281 (0.3352)  loss_giou_dn_1: 1.3402 (1.3824)  loss_vfl_dn_2: 0.3809 (0.4366)  loss_bbox_dn_2: 0.2266 (0.3349)  loss_giou_dn_2: 1.3447 (1.3931)  loss_vfl_dn_3: 0.3902 (0.4423)  loss_bbox_dn_3: 0.2259 (0.3349)  loss_giou_dn_3: 1.3382 (1.4033)  loss_vfl_dn_4: 0.4008 (0.4534)  loss_bbox_dn_4: 0.2250 (0.3350)  loss_giou_dn_4: 1.3453 (1.4141)  loss_vfl_dn_5: 0.3951 (0.4518)  loss_bbox_dn_5: 0.2247 (0.3352)  loss_giou_dn_5: 1.3582 (1.4255)  time: 0.4833  data: 0.0042  max mem: 5457\n",
      "Epoch: [0]  [ 300/1348]  eta: 0:09:14  lr: 0.000010  loss: 28.3866 (31.2790)  loss_vfl: 0.7119 (0.5111)  loss_bbox: 0.3178 (0.5707)  loss_giou: 1.3223 (1.5746)  loss_vfl_aux_0: 0.4154 (0.4012)  loss_bbox_aux_0: 0.4377 (0.6066)  loss_giou_aux_0: 1.5825 (1.6200)  loss_vfl_aux_1: 0.5792 (0.4262)  loss_bbox_aux_1: 0.3561 (0.5915)  loss_giou_aux_1: 1.4266 (1.6009)  loss_vfl_aux_2: 0.5091 (0.4513)  loss_bbox_aux_2: 0.3518 (0.5878)  loss_giou_aux_2: 1.3623 (1.5896)  loss_vfl_aux_3: 0.6024 (0.4703)  loss_bbox_aux_3: 0.3378 (0.5792)  loss_giou_aux_3: 1.3704 (1.5838)  loss_vfl_aux_4: 0.6787 (0.4884)  loss_bbox_aux_4: 0.3242 (0.5781)  loss_giou_aux_4: 1.3384 (1.5771)  loss_vfl_aux_5: 0.3334 (0.3690)  loss_bbox_aux_5: 0.4832 (0.6301)  loss_giou_aux_5: 1.6316 (1.6442)  loss_vfl_dn_0: 0.3795 (0.4148)  loss_bbox_dn_0: 0.2742 (0.3311)  loss_giou_dn_0: 1.3029 (1.3647)  loss_vfl_dn_1: 0.3871 (0.4111)  loss_bbox_dn_1: 0.2718 (0.3296)  loss_giou_dn_1: 1.3116 (1.3710)  loss_vfl_dn_2: 0.3828 (0.4205)  loss_bbox_dn_2: 0.2687 (0.3289)  loss_giou_dn_2: 1.2972 (1.3800)  loss_vfl_dn_3: 0.3946 (0.4260)  loss_bbox_dn_3: 0.2686 (0.3287)  loss_giou_dn_3: 1.2862 (1.3886)  loss_vfl_dn_4: 0.4027 (0.4345)  loss_bbox_dn_4: 0.2691 (0.3287)  loss_giou_dn_4: 1.2992 (1.3977)  loss_vfl_dn_5: 0.4149 (0.4353)  loss_bbox_dn_5: 0.2707 (0.3288)  loss_giou_dn_5: 1.2903 (1.4074)  time: 0.4920  data: 0.0044  max mem: 5457\n",
      "Epoch: [0]  [ 400/1348]  eta: 0:08:15  lr: 0.000010  loss: 27.9387 (30.9668)  loss_vfl: 0.6556 (0.5643)  loss_bbox: 0.2980 (0.5410)  loss_giou: 1.2790 (1.5052)  loss_vfl_aux_0: 0.5595 (0.4259)  loss_bbox_aux_0: 0.3977 (0.5974)  loss_giou_aux_0: 1.3356 (1.5774)  loss_vfl_aux_1: 0.5720 (0.4652)  loss_bbox_aux_1: 0.3098 (0.5715)  loss_giou_aux_1: 1.3058 (1.5425)  loss_vfl_aux_2: 0.6437 (0.4998)  loss_bbox_aux_2: 0.3145 (0.5626)  loss_giou_aux_2: 1.2596 (1.5225)  loss_vfl_aux_3: 0.6627 (0.5212)  loss_bbox_aux_3: 0.3372 (0.5517)  loss_giou_aux_3: 1.2764 (1.5154)  loss_vfl_aux_4: 0.6849 (0.5390)  loss_bbox_aux_4: 0.3321 (0.5501)  loss_giou_aux_4: 1.2997 (1.5105)  loss_vfl_aux_5: 0.4366 (0.3829)  loss_bbox_aux_5: 0.4876 (0.6284)  loss_giou_aux_5: 1.4779 (1.6167)  loss_vfl_dn_0: 0.3781 (0.4056)  loss_bbox_dn_0: 0.3641 (0.3439)  loss_giou_dn_0: 1.3355 (1.3574)  loss_vfl_dn_1: 0.3777 (0.4041)  loss_bbox_dn_1: 0.3615 (0.3419)  loss_giou_dn_1: 1.3016 (1.3601)  loss_vfl_dn_2: 0.3904 (0.4128)  loss_bbox_dn_2: 0.3614 (0.3411)  loss_giou_dn_2: 1.2970 (1.3656)  loss_vfl_dn_3: 0.3887 (0.4194)  loss_bbox_dn_3: 0.3628 (0.3415)  loss_giou_dn_3: 1.2931 (1.3721)  loss_vfl_dn_4: 0.3986 (0.4268)  loss_bbox_dn_4: 0.3632 (0.3421)  loss_giou_dn_4: 1.2908 (1.3802)  loss_vfl_dn_5: 0.4093 (0.4298)  loss_bbox_dn_5: 0.3683 (0.3429)  loss_giou_dn_5: 1.2776 (1.3883)  time: 0.5105  data: 0.0061  max mem: 5458\n",
      "Epoch: [0]  [ 500/1348]  eta: 0:07:23  lr: 0.000010  loss: 28.5281 (30.5909)  loss_vfl: 0.8443 (0.6054)  loss_bbox: 0.3469 (0.5039)  loss_giou: 1.1577 (1.4550)  loss_vfl_aux_0: 0.6740 (0.4544)  loss_bbox_aux_0: 0.3829 (0.5714)  loss_giou_aux_0: 1.2561 (1.5442)  loss_vfl_aux_1: 0.7760 (0.5088)  loss_bbox_aux_1: 0.3615 (0.5393)  loss_giou_aux_1: 1.1812 (1.4959)  loss_vfl_aux_2: 0.7553 (0.5433)  loss_bbox_aux_2: 0.3311 (0.5278)  loss_giou_aux_2: 1.1586 (1.4737)  loss_vfl_aux_3: 0.8165 (0.5677)  loss_bbox_aux_3: 0.3141 (0.5152)  loss_giou_aux_3: 1.1547 (1.4652)  loss_vfl_aux_4: 0.7925 (0.5815)  loss_bbox_aux_4: 0.3458 (0.5121)  loss_giou_aux_4: 1.1786 (1.4608)  loss_vfl_aux_5: 0.5325 (0.4026)  loss_bbox_aux_5: 0.4268 (0.6052)  loss_giou_aux_5: 1.4123 (1.5937)  loss_vfl_dn_0: 0.3789 (0.4016)  loss_bbox_dn_0: 0.3335 (0.3434)  loss_giou_dn_0: 1.3058 (1.3493)  loss_vfl_dn_1: 0.4009 (0.4034)  loss_bbox_dn_1: 0.3308 (0.3405)  loss_giou_dn_1: 1.2518 (1.3450)  loss_vfl_dn_2: 0.4089 (0.4119)  loss_bbox_dn_2: 0.3374 (0.3398)  loss_giou_dn_2: 1.2403 (1.3479)  loss_vfl_dn_3: 0.4284 (0.4195)  loss_bbox_dn_3: 0.3420 (0.3403)  loss_giou_dn_3: 1.2312 (1.3529)  loss_vfl_dn_4: 0.4427 (0.4271)  loss_bbox_dn_4: 0.3429 (0.3411)  loss_giou_dn_4: 1.2214 (1.3596)  loss_vfl_dn_5: 0.4473 (0.4312)  loss_bbox_dn_5: 0.3454 (0.3421)  loss_giou_dn_5: 1.2110 (1.3670)  time: 0.5114  data: 0.0050  max mem: 5458\n",
      "Epoch: [0]  [ 600/1348]  eta: 0:06:35  lr: 0.000010  loss: 27.7372 (30.2003)  loss_vfl: 0.8498 (0.6454)  loss_bbox: 0.2377 (0.4718)  loss_giou: 1.1689 (1.4118)  loss_vfl_aux_0: 0.7139 (0.4987)  loss_bbox_aux_0: 0.2429 (0.5376)  loss_giou_aux_0: 1.1593 (1.4954)  loss_vfl_aux_1: 0.7400 (0.5519)  loss_bbox_aux_1: 0.2359 (0.5057)  loss_giou_aux_1: 1.1456 (1.4490)  loss_vfl_aux_2: 0.7687 (0.5839)  loss_bbox_aux_2: 0.2406 (0.4945)  loss_giou_aux_2: 1.1355 (1.4287)  loss_vfl_aux_3: 0.8197 (0.6064)  loss_bbox_aux_3: 0.2343 (0.4823)  loss_giou_aux_3: 1.1192 (1.4215)  loss_vfl_aux_4: 0.8825 (0.6215)  loss_bbox_aux_4: 0.2415 (0.4791)  loss_giou_aux_4: 1.1011 (1.4170)  loss_vfl_aux_5: 0.5695 (0.4377)  loss_bbox_aux_5: 0.3267 (0.5756)  loss_giou_aux_5: 1.3211 (1.5563)  loss_vfl_dn_0: 0.3866 (0.3996)  loss_bbox_dn_0: 0.2674 (0.3381)  loss_giou_dn_0: 1.3073 (1.3392)  loss_vfl_dn_1: 0.3969 (0.4038)  loss_bbox_dn_1: 0.2561 (0.3349)  loss_giou_dn_1: 1.2384 (1.3287)  loss_vfl_dn_2: 0.4045 (0.4131)  loss_bbox_dn_2: 0.2540 (0.3344)  loss_giou_dn_2: 1.2194 (1.3295)  loss_vfl_dn_3: 0.4072 (0.4205)  loss_bbox_dn_3: 0.2509 (0.3350)  loss_giou_dn_3: 1.2243 (1.3329)  loss_vfl_dn_4: 0.4217 (0.4288)  loss_bbox_dn_4: 0.2477 (0.3357)  loss_giou_dn_4: 1.2342 (1.3388)  loss_vfl_dn_5: 0.4281 (0.4333)  loss_bbox_dn_5: 0.2459 (0.3367)  loss_giou_dn_5: 1.2388 (1.3454)  time: 0.5853  data: 0.0403  max mem: 5458\n",
      "Epoch: [0]  [ 700/1348]  eta: 0:05:51  lr: 0.000010  loss: 26.9986 (29.8591)  loss_vfl: 0.8120 (0.6755)  loss_bbox: 0.1923 (0.4461)  loss_giou: 1.1632 (1.3765)  loss_vfl_aux_0: 0.6609 (0.5329)  loss_bbox_aux_0: 0.2280 (0.5074)  loss_giou_aux_0: 1.2583 (1.4573)  loss_vfl_aux_1: 0.7213 (0.5849)  loss_bbox_aux_1: 0.2116 (0.4760)  loss_giou_aux_1: 1.2134 (1.4121)  loss_vfl_aux_2: 0.7977 (0.6162)  loss_bbox_aux_2: 0.2054 (0.4657)  loss_giou_aux_2: 1.1965 (1.3919)  loss_vfl_aux_3: 0.8117 (0.6380)  loss_bbox_aux_3: 0.2116 (0.4548)  loss_giou_aux_3: 1.1835 (1.3852)  loss_vfl_aux_4: 0.7857 (0.6513)  loss_bbox_aux_4: 0.1995 (0.4521)  loss_giou_aux_4: 1.1713 (1.3808)  loss_vfl_aux_5: 0.5710 (0.4607)  loss_bbox_aux_5: 0.3118 (0.5478)  loss_giou_aux_5: 1.2944 (1.5295)  loss_vfl_dn_0: 0.3908 (0.3993)  loss_bbox_dn_0: 0.2241 (0.3338)  loss_giou_dn_0: 1.2556 (1.3290)  loss_vfl_dn_1: 0.4017 (0.4048)  loss_bbox_dn_1: 0.2197 (0.3301)  loss_giou_dn_1: 1.2166 (1.3148)  loss_vfl_dn_2: 0.4234 (0.4145)  loss_bbox_dn_2: 0.2209 (0.3295)  loss_giou_dn_2: 1.1992 (1.3143)  loss_vfl_dn_3: 0.4209 (0.4219)  loss_bbox_dn_3: 0.2209 (0.3299)  loss_giou_dn_3: 1.1895 (1.3169)  loss_vfl_dn_4: 0.4196 (0.4303)  loss_bbox_dn_4: 0.2198 (0.3302)  loss_giou_dn_4: 1.1863 (1.3222)  loss_vfl_dn_5: 0.4249 (0.4356)  loss_bbox_dn_5: 0.2180 (0.3311)  loss_giou_dn_5: 1.1929 (1.3281)  time: 0.5948  data: 0.0217  max mem: 5458\n",
      "Epoch: [0]  [ 800/1348]  eta: 0:05:01  lr: 0.000010  loss: 27.1342 (29.6198)  loss_vfl: 0.8510 (0.6983)  loss_bbox: 0.2561 (0.4270)  loss_giou: 1.0649 (1.3492)  loss_vfl_aux_0: 0.7167 (0.5606)  loss_bbox_aux_0: 0.2399 (0.4856)  loss_giou_aux_0: 1.1517 (1.4270)  loss_vfl_aux_1: 0.7417 (0.6116)  loss_bbox_aux_1: 0.2738 (0.4557)  loss_giou_aux_1: 1.1270 (1.3840)  loss_vfl_aux_2: 0.7984 (0.6413)  loss_bbox_aux_2: 0.2362 (0.4450)  loss_giou_aux_2: 1.0966 (1.3646)  loss_vfl_aux_3: 0.7618 (0.6622)  loss_bbox_aux_3: 0.2305 (0.4346)  loss_giou_aux_3: 1.0632 (1.3569)  loss_vfl_aux_4: 0.7614 (0.6734)  loss_bbox_aux_4: 0.2482 (0.4322)  loss_giou_aux_4: 1.0846 (1.3533)  loss_vfl_aux_5: 0.6691 (0.4801)  loss_bbox_aux_5: 0.3035 (0.5282)  loss_giou_aux_5: 1.3165 (1.5069)  loss_vfl_dn_0: 0.4188 (0.3997)  loss_bbox_dn_0: 0.2850 (0.3324)  loss_giou_dn_0: 1.2125 (1.3196)  loss_vfl_dn_1: 0.4207 (0.4061)  loss_bbox_dn_1: 0.2802 (0.3283)  loss_giou_dn_1: 1.1613 (1.3035)  loss_vfl_dn_2: 0.4401 (0.4166)  loss_bbox_dn_2: 0.2792 (0.3277)  loss_giou_dn_2: 1.1465 (1.3019)  loss_vfl_dn_3: 0.4347 (0.4239)  loss_bbox_dn_3: 0.2779 (0.3280)  loss_giou_dn_3: 1.1477 (1.3040)  loss_vfl_dn_4: 0.4456 (0.4327)  loss_bbox_dn_4: 0.2783 (0.3281)  loss_giou_dn_4: 1.1413 (1.3086)  loss_vfl_dn_5: 0.4547 (0.4380)  loss_bbox_dn_5: 0.2784 (0.3288)  loss_giou_dn_5: 1.1425 (1.3139)  time: 0.6503  data: 0.0079  max mem: 5458\n",
      "Epoch: [0]  [ 900/1348]  eta: 0:04:11  lr: 0.000010  loss: 27.3656 (29.3941)  loss_vfl: 0.8129 (0.7187)  loss_bbox: 0.2759 (0.4089)  loss_giou: 1.1750 (1.3283)  loss_vfl_aux_0: 0.7166 (0.5823)  loss_bbox_aux_0: 0.2805 (0.4653)  loss_giou_aux_0: 1.2129 (1.4047)  loss_vfl_aux_1: 0.7667 (0.6306)  loss_bbox_aux_1: 0.3049 (0.4372)  loss_giou_aux_1: 1.2058 (1.3634)  loss_vfl_aux_2: 0.7088 (0.6621)  loss_bbox_aux_2: 0.2911 (0.4260)  loss_giou_aux_2: 1.2317 (1.3439)  loss_vfl_aux_3: 0.8181 (0.6823)  loss_bbox_aux_3: 0.2906 (0.4166)  loss_giou_aux_3: 1.1870 (1.3359)  loss_vfl_aux_4: 0.7925 (0.6937)  loss_bbox_aux_4: 0.2947 (0.4139)  loss_giou_aux_4: 1.1898 (1.3325)  loss_vfl_aux_5: 0.5946 (0.4967)  loss_bbox_aux_5: 0.3251 (0.5116)  loss_giou_aux_5: 1.3199 (1.4899)  loss_vfl_dn_0: 0.4042 (0.4007)  loss_bbox_dn_0: 0.3267 (0.3285)  loss_giou_dn_0: 1.2243 (1.3101)  loss_vfl_dn_1: 0.4183 (0.4086)  loss_bbox_dn_1: 0.2992 (0.3240)  loss_giou_dn_1: 1.1748 (1.2909)  loss_vfl_dn_2: 0.4254 (0.4195)  loss_bbox_dn_2: 0.3115 (0.3231)  loss_giou_dn_2: 1.1789 (1.2880)  loss_vfl_dn_3: 0.4302 (0.4269)  loss_bbox_dn_3: 0.3075 (0.3232)  loss_giou_dn_3: 1.1720 (1.2895)  loss_vfl_dn_4: 0.4319 (0.4357)  loss_bbox_dn_4: 0.3020 (0.3232)  loss_giou_dn_4: 1.1650 (1.2937)  loss_vfl_dn_5: 0.4436 (0.4419)  loss_bbox_dn_5: 0.2993 (0.3237)  loss_giou_dn_5: 1.1557 (1.2984)  time: 0.7454  data: 0.1345  max mem: 5458\n",
      "Epoch: [0]  [1000/1348]  eta: 0:03:15  lr: 0.000010  loss: 26.7865 (29.1693)  loss_vfl: 0.7850 (0.7323)  loss_bbox: 0.2378 (0.3937)  loss_giou: 1.0884 (1.3105)  loss_vfl_aux_0: 0.7360 (0.6003)  loss_bbox_aux_0: 0.2346 (0.4473)  loss_giou_aux_0: 1.1053 (1.3833)  loss_vfl_aux_1: 0.7587 (0.6456)  loss_bbox_aux_1: 0.2253 (0.4208)  loss_giou_aux_1: 1.0508 (1.3448)  loss_vfl_aux_2: 0.7633 (0.6753)  loss_bbox_aux_2: 0.2350 (0.4103)  loss_giou_aux_2: 1.1316 (1.3263)  loss_vfl_aux_3: 0.7495 (0.6946)  loss_bbox_aux_3: 0.2318 (0.4012)  loss_giou_aux_3: 1.1034 (1.3189)  loss_vfl_aux_4: 0.7725 (0.7075)  loss_bbox_aux_4: 0.2322 (0.3989)  loss_giou_aux_4: 1.1009 (1.3148)  loss_vfl_aux_5: 0.5400 (0.5119)  loss_bbox_aux_5: 0.2751 (0.4950)  loss_giou_aux_5: 1.2851 (1.4727)  loss_vfl_dn_0: 0.4210 (0.4020)  loss_bbox_dn_0: 0.2782 (0.3243)  loss_giou_dn_0: 1.1920 (1.3005)  loss_vfl_dn_1: 0.4234 (0.4105)  loss_bbox_dn_1: 0.2774 (0.3193)  loss_giou_dn_1: 1.1560 (1.2794)  loss_vfl_dn_2: 0.4283 (0.4216)  loss_bbox_dn_2: 0.2754 (0.3182)  loss_giou_dn_2: 1.1345 (1.2760)  loss_vfl_dn_3: 0.4325 (0.4293)  loss_bbox_dn_3: 0.2742 (0.3182)  loss_giou_dn_3: 1.1337 (1.2773)  loss_vfl_dn_4: 0.4431 (0.4385)  loss_bbox_dn_4: 0.2729 (0.3180)  loss_giou_dn_4: 1.1400 (1.2811)  loss_vfl_dn_5: 0.4452 (0.4449)  loss_bbox_dn_5: 0.2740 (0.3185)  loss_giou_dn_5: 1.1566 (1.2856)  time: 0.5060  data: 0.0046  max mem: 5458\n",
      "Epoch: [0]  [1100/1348]  eta: 0:02:18  lr: 0.000010  loss: 25.6772 (29.0060)  loss_vfl: 0.6718 (0.7443)  loss_bbox: 0.1921 (0.3821)  loss_giou: 1.1928 (1.2962)  loss_vfl_aux_0: 0.6991 (0.6163)  loss_bbox_aux_0: 0.2068 (0.4330)  loss_giou_aux_0: 1.2191 (1.3667)  loss_vfl_aux_1: 0.6973 (0.6593)  loss_bbox_aux_1: 0.2036 (0.4082)  loss_giou_aux_1: 1.2082 (1.3295)  loss_vfl_aux_2: 0.6687 (0.6879)  loss_bbox_aux_2: 0.1975 (0.3979)  loss_giou_aux_2: 1.1706 (1.3119)  loss_vfl_aux_3: 0.7211 (0.7079)  loss_bbox_aux_3: 0.2016 (0.3893)  loss_giou_aux_3: 1.1722 (1.3042)  loss_vfl_aux_4: 0.6750 (0.7207)  loss_bbox_aux_4: 0.1863 (0.3869)  loss_giou_aux_4: 1.1729 (1.3007)  loss_vfl_aux_5: 0.5812 (0.5271)  loss_bbox_aux_5: 0.2132 (0.4809)  loss_giou_aux_5: 1.2931 (1.4578)  loss_vfl_dn_0: 0.4117 (0.4037)  loss_bbox_dn_0: 0.2009 (0.3224)  loss_giou_dn_0: 1.2621 (1.2922)  loss_vfl_dn_1: 0.4195 (0.4130)  loss_bbox_dn_1: 0.1976 (0.3170)  loss_giou_dn_1: 1.2081 (1.2685)  loss_vfl_dn_2: 0.4374 (0.4245)  loss_bbox_dn_2: 0.1843 (0.3156)  loss_giou_dn_2: 1.1834 (1.2641)  loss_vfl_dn_3: 0.4511 (0.4326)  loss_bbox_dn_3: 0.1840 (0.3156)  loss_giou_dn_3: 1.1755 (1.2650)  loss_vfl_dn_4: 0.4630 (0.4422)  loss_bbox_dn_4: 0.1820 (0.3153)  loss_giou_dn_4: 1.1687 (1.2685)  loss_vfl_dn_5: 0.4663 (0.4489)  loss_bbox_dn_5: 0.1807 (0.3157)  loss_giou_dn_5: 1.1705 (1.2727)  time: 0.6074  data: 0.0056  max mem: 5458\n",
      "Epoch: [0]  [1200/1348]  eta: 0:01:23  lr: 0.000010  loss: 26.3032 (28.8183)  loss_vfl: 0.9112 (0.7609)  loss_bbox: 0.1897 (0.3701)  loss_giou: 0.9409 (1.2759)  loss_vfl_aux_0: 0.8813 (0.6332)  loss_bbox_aux_0: 0.2234 (0.4184)  loss_giou_aux_0: 1.0045 (1.3471)  loss_vfl_aux_1: 0.9008 (0.6767)  loss_bbox_aux_1: 0.1867 (0.3947)  loss_giou_aux_1: 0.9506 (1.3092)  loss_vfl_aux_2: 0.9788 (0.7054)  loss_bbox_aux_2: 0.1657 (0.3849)  loss_giou_aux_2: 0.9668 (1.2911)  loss_vfl_aux_3: 0.9379 (0.7247)  loss_bbox_aux_3: 0.1801 (0.3766)  loss_giou_aux_3: 0.9412 (1.2840)  loss_vfl_aux_4: 0.9675 (0.7380)  loss_bbox_aux_4: 0.1981 (0.3744)  loss_giou_aux_4: 0.9524 (1.2805)  loss_vfl_aux_5: 0.6939 (0.5427)  loss_bbox_aux_5: 0.2620 (0.4663)  loss_giou_aux_5: 1.2171 (1.4424)  loss_vfl_dn_0: 0.4343 (0.4060)  loss_bbox_dn_0: 0.2194 (0.3189)  loss_giou_dn_0: 1.1542 (1.2833)  loss_vfl_dn_1: 0.4563 (0.4163)  loss_bbox_dn_1: 0.1988 (0.3129)  loss_giou_dn_1: 1.0844 (1.2571)  loss_vfl_dn_2: 0.4634 (0.4276)  loss_bbox_dn_2: 0.1891 (0.3113)  loss_giou_dn_2: 1.0481 (1.2521)  loss_vfl_dn_3: 0.4681 (0.4359)  loss_bbox_dn_3: 0.1887 (0.3111)  loss_giou_dn_3: 1.0355 (1.2527)  loss_vfl_dn_4: 0.4836 (0.4459)  loss_bbox_dn_4: 0.1876 (0.3107)  loss_giou_dn_4: 1.0382 (1.2558)  loss_vfl_dn_5: 0.4938 (0.4528)  loss_bbox_dn_5: 0.1877 (0.3111)  loss_giou_dn_5: 1.0351 (1.2597)  time: 0.5501  data: 0.0046  max mem: 5458\n",
      "Epoch: [0]  [1300/1348]  eta: 0:00:26  lr: 0.000010  loss: 27.1270 (28.6673)  loss_vfl: 0.8846 (0.7720)  loss_bbox: 0.2702 (0.3595)  loss_giou: 1.0666 (1.2647)  loss_vfl_aux_0: 0.7723 (0.6445)  loss_bbox_aux_0: 0.2737 (0.4060)  loss_giou_aux_0: 1.1328 (1.3354)  loss_vfl_aux_1: 0.8186 (0.6892)  loss_bbox_aux_1: 0.2722 (0.3831)  loss_giou_aux_1: 1.0846 (1.2967)  loss_vfl_aux_2: 0.8325 (0.7172)  loss_bbox_aux_2: 0.2770 (0.3738)  loss_giou_aux_2: 1.0608 (1.2793)  loss_vfl_aux_3: 0.8205 (0.7366)  loss_bbox_aux_3: 0.2762 (0.3659)  loss_giou_aux_3: 1.0717 (1.2721)  loss_vfl_aux_4: 0.8596 (0.7496)  loss_bbox_aux_4: 0.2705 (0.3639)  loss_giou_aux_4: 1.0750 (1.2687)  loss_vfl_aux_5: 0.7239 (0.5545)  loss_bbox_aux_5: 0.2938 (0.4526)  loss_giou_aux_5: 1.2762 (1.4318)  loss_vfl_dn_0: 0.4145 (0.4077)  loss_bbox_dn_0: 0.2866 (0.3144)  loss_giou_dn_0: 1.1665 (1.2756)  loss_vfl_dn_1: 0.4302 (0.4185)  loss_bbox_dn_1: 0.3124 (0.3083)  loss_giou_dn_1: 1.1297 (1.2479)  loss_vfl_dn_2: 0.4399 (0.4299)  loss_bbox_dn_2: 0.3065 (0.3065)  loss_giou_dn_2: 1.1322 (1.2426)  loss_vfl_dn_3: 0.4477 (0.4384)  loss_bbox_dn_3: 0.3041 (0.3062)  loss_giou_dn_3: 1.1310 (1.2430)  loss_vfl_dn_4: 0.4648 (0.4484)  loss_bbox_dn_4: 0.3043 (0.3057)  loss_giou_dn_4: 1.1289 (1.2460)  loss_vfl_dn_5: 0.4759 (0.4557)  loss_bbox_dn_5: 0.3045 (0.3060)  loss_giou_dn_5: 1.1270 (1.2496)  time: 0.5346  data: 0.0050  max mem: 5458\n",
      "Epoch: [0]  [1347/1348]  eta: 0:00:00  lr: 0.000010  loss: 26.1872 (28.5879)  loss_vfl: 0.8896 (0.7756)  loss_bbox: 0.1615 (0.3550)  loss_giou: 1.0420 (1.2588)  loss_vfl_aux_0: 0.7595 (0.6487)  loss_bbox_aux_0: 0.1935 (0.4003)  loss_giou_aux_0: 1.0925 (1.3298)  loss_vfl_aux_1: 0.8148 (0.6935)  loss_bbox_aux_1: 0.1780 (0.3778)  loss_giou_aux_1: 1.0586 (1.2915)  loss_vfl_aux_2: 0.8762 (0.7217)  loss_bbox_aux_2: 0.1910 (0.3689)  loss_giou_aux_2: 1.0340 (1.2732)  loss_vfl_aux_3: 0.8743 (0.7410)  loss_bbox_aux_3: 0.1897 (0.3611)  loss_giou_aux_3: 1.0408 (1.2663)  loss_vfl_aux_4: 0.9301 (0.7540)  loss_bbox_aux_4: 0.1657 (0.3593)  loss_giou_aux_4: 1.0398 (1.2627)  loss_vfl_aux_5: 0.7571 (0.5598)  loss_bbox_aux_5: 0.2130 (0.4463)  loss_giou_aux_5: 1.2105 (1.4264)  loss_vfl_dn_0: 0.4224 (0.4083)  loss_bbox_dn_0: 0.1711 (0.3124)  loss_giou_dn_0: 1.1875 (1.2722)  loss_vfl_dn_1: 0.4317 (0.4193)  loss_bbox_dn_1: 0.1608 (0.3061)  loss_giou_dn_1: 1.1378 (1.2436)  loss_vfl_dn_2: 0.4271 (0.4308)  loss_bbox_dn_2: 0.1629 (0.3042)  loss_giou_dn_2: 1.1352 (1.2380)  loss_vfl_dn_3: 0.4527 (0.4394)  loss_bbox_dn_3: 0.1643 (0.3039)  loss_giou_dn_3: 1.1342 (1.2384)  loss_vfl_dn_4: 0.4582 (0.4495)  loss_bbox_dn_4: 0.1668 (0.3034)  loss_giou_dn_4: 1.1317 (1.2412)  loss_vfl_dn_5: 0.4733 (0.4568)  loss_bbox_dn_5: 0.1680 (0.3037)  loss_giou_dn_5: 1.1381 (1.2449)  time: 0.5178  data: 0.0043  max mem: 5458\n",
      "Epoch: [0] Total time: 0:12:34 (0.5596 s / it)\n",
      "Averaged stats: lr: 0.000010  loss: 26.1872 (28.5879)  loss_vfl: 0.8896 (0.7756)  loss_bbox: 0.1615 (0.3550)  loss_giou: 1.0420 (1.2588)  loss_vfl_aux_0: 0.7595 (0.6487)  loss_bbox_aux_0: 0.1935 (0.4003)  loss_giou_aux_0: 1.0925 (1.3298)  loss_vfl_aux_1: 0.8148 (0.6935)  loss_bbox_aux_1: 0.1780 (0.3778)  loss_giou_aux_1: 1.0586 (1.2915)  loss_vfl_aux_2: 0.8762 (0.7217)  loss_bbox_aux_2: 0.1910 (0.3689)  loss_giou_aux_2: 1.0340 (1.2732)  loss_vfl_aux_3: 0.8743 (0.7410)  loss_bbox_aux_3: 0.1897 (0.3611)  loss_giou_aux_3: 1.0408 (1.2663)  loss_vfl_aux_4: 0.9301 (0.7540)  loss_bbox_aux_4: 0.1657 (0.3593)  loss_giou_aux_4: 1.0398 (1.2627)  loss_vfl_aux_5: 0.7571 (0.5598)  loss_bbox_aux_5: 0.2130 (0.4463)  loss_giou_aux_5: 1.2105 (1.4264)  loss_vfl_dn_0: 0.4224 (0.4083)  loss_bbox_dn_0: 0.1711 (0.3124)  loss_giou_dn_0: 1.1875 (1.2722)  loss_vfl_dn_1: 0.4317 (0.4193)  loss_bbox_dn_1: 0.1608 (0.3061)  loss_giou_dn_1: 1.1378 (1.2436)  loss_vfl_dn_2: 0.4271 (0.4308)  loss_bbox_dn_2: 0.1629 (0.3042)  loss_giou_dn_2: 1.1352 (1.2380)  loss_vfl_dn_3: 0.4527 (0.4394)  loss_bbox_dn_3: 0.1643 (0.3039)  loss_giou_dn_3: 1.1342 (1.2384)  loss_vfl_dn_4: 0.4582 (0.4495)  loss_bbox_dn_4: 0.1668 (0.3034)  loss_giou_dn_4: 1.1317 (1.2412)  loss_vfl_dn_5: 0.4733 (0.4568)  loss_bbox_dn_5: 0.1680 (0.3037)  loss_giou_dn_5: 1.1381 (1.2449)\n",
      "Test:  [  0/110]  eta: 0:22:42    time: 12.3867  data: 11.0634  max mem: 5458\n",
      "Test:  [ 10/110]  eta: 0:03:01    time: 1.8158  data: 1.0134  max mem: 5458\n",
      "Test:  [ 20/110]  eta: 0:01:58    time: 0.7648  data: 0.0095  max mem: 5458\n",
      "Test:  [ 30/110]  eta: 0:01:31    time: 0.7677  data: 0.0095  max mem: 5458\n",
      "Test:  [ 40/110]  eta: 0:01:13    time: 0.7545  data: 0.0086  max mem: 5458\n",
      "Test:  [ 50/110]  eta: 0:00:59    time: 0.7496  data: 0.0088  max mem: 5458\n",
      "Test:  [ 60/110]  eta: 0:00:47    time: 0.7635  data: 0.0092  max mem: 5458\n",
      "Test:  [ 70/110]  eta: 0:00:36    time: 0.7502  data: 0.0090  max mem: 5458\n",
      "Test:  [ 80/110]  eta: 0:00:26    time: 0.7314  data: 0.0085  max mem: 5458\n",
      "Test:  [ 90/110]  eta: 0:00:17    time: 0.7292  data: 0.0087  max mem: 5458\n",
      "Test:  [100/110]  eta: 0:00:08    time: 0.7288  data: 0.0088  max mem: 5458\n",
      "Test:  [109/110]  eta: 0:00:00    time: 0.7282  data: 0.0083  max mem: 5458\n",
      "Test: Total time: 0:01:34 (0.8557 s / it)\n",
      "Averaged stats: \n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.73s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001\n",
      "最佳状态:  {'epoch': 0, 'coco_eval_bbox': 1.0739287878716422e-07}\n",
      "训练总时长 0:14:10\n"
     ]
    }
   ],
   "source": [
    "solver.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rtdetr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
